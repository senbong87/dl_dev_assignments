{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from itertools import islice\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler, \\\n",
    "                            ReduceLROnPlateau, TensorBoard\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scaler(X, max_num=100):\n",
    "    return X.astype(np.float) / max_num\n",
    "\n",
    "\n",
    "def data_generator(batch_size=128, max_num=100, excludes=[50], num_class=201, scaler=None,\n",
    "                   is_train=True):\n",
    "    while True:\n",
    "        if is_train:\n",
    "            X = np.random.randint(low=0, high=max_num+1, size=(batch_size, 2)).astype(np.float)\n",
    "            rand_iter = iter(lambda: np.random.randint(max_num+1), max_num+1)\n",
    "            X[np.isin(X, excludes)] = next(x for x in rand_iter if x not in excludes)\n",
    "        else:\n",
    "            X1 = np.random.choice(excludes, size=batch_size)\n",
    "            X2 = np.random.randint(low=0, high=max_num+1, size=batch_size)\n",
    "            X = np.vstack((X1, X2)).T\n",
    "        y = np_utils.to_categorical(X.sum(axis=1), num_class)\n",
    "        if scaler:\n",
    "            X = scaler(X)\n",
    "        yield X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "Dense_1 (Dense)              (None, 50)                150       \n",
      "_________________________________________________________________\n",
      "Dense_2 (Dense)              (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 201)               20301     \n",
      "=================================================================\n",
      "Total params: 25,551\n",
      "Trainable params: 25,551\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/500\n",
      "100/100 [==============================] - 0s - loss: 3.6482 - acc: 0.0652 - val_loss: 3.0981 - val_acc: 0.1270\n",
      "Epoch 2/500\n",
      "100/100 [==============================] - 0s - loss: 2.6573 - acc: 0.1440 - val_loss: 2.5415 - val_acc: 0.1416\n",
      "Epoch 3/500\n",
      "100/100 [==============================] - 0s - loss: 2.2909 - acc: 0.2009 - val_loss: 2.2707 - val_acc: 0.2500\n",
      "Epoch 4/500\n",
      "100/100 [==============================] - 0s - loss: 2.0692 - acc: 0.2511 - val_loss: 1.9502 - val_acc: 0.3174\n",
      "Epoch 5/500\n",
      "100/100 [==============================] - 0s - loss: 1.8990 - acc: 0.2971 - val_loss: 2.0509 - val_acc: 0.2891\n",
      "Epoch 6/500\n",
      "100/100 [==============================] - 0s - loss: 1.7854 - acc: 0.3281 - val_loss: 1.7581 - val_acc: 0.4551\n",
      "Epoch 7/500\n",
      "100/100 [==============================] - 0s - loss: 1.6611 - acc: 0.3707 - val_loss: 1.7832 - val_acc: 0.3535\n",
      "Epoch 8/500\n",
      "100/100 [==============================] - 0s - loss: 1.5563 - acc: 0.4142 - val_loss: 1.7025 - val_acc: 0.3818\n",
      "Epoch 9/500\n",
      "100/100 [==============================] - 0s - loss: 1.5526 - acc: 0.4047 - val_loss: 1.6403 - val_acc: 0.4834\n",
      "Epoch 10/500\n",
      "100/100 [==============================] - 0s - loss: 1.3776 - acc: 0.4966 - val_loss: 1.4719 - val_acc: 0.4277\n",
      "Epoch 11/500\n",
      "100/100 [==============================] - 0s - loss: 1.3383 - acc: 0.5034 - val_loss: 1.5928 - val_acc: 0.4639\n",
      "Epoch 12/500\n",
      "100/100 [==============================] - 0s - loss: 1.3103 - acc: 0.5141 - val_loss: 1.4082 - val_acc: 0.4785\n",
      "Epoch 13/500\n",
      "100/100 [==============================] - 0s - loss: 1.2750 - acc: 0.5187 - val_loss: 1.4645 - val_acc: 0.5498\n",
      "Epoch 14/500\n",
      "100/100 [==============================] - 0s - loss: 1.1455 - acc: 0.6144 - val_loss: 1.3292 - val_acc: 0.6104\n",
      "Epoch 15/500\n",
      "100/100 [==============================] - 0s - loss: 1.1037 - acc: 0.6362 - val_loss: 1.1354 - val_acc: 0.6416\n",
      "Epoch 16/500\n",
      "100/100 [==============================] - 0s - loss: 1.0788 - acc: 0.6141 - val_loss: 1.2083 - val_acc: 0.6514\n",
      "Epoch 17/500\n",
      "100/100 [==============================] - 0s - loss: 1.0188 - acc: 0.6734 - val_loss: 1.3625 - val_acc: 0.6611\n",
      "Epoch 18/500\n",
      "100/100 [==============================] - 0s - loss: 1.1917 - acc: 0.5647 - val_loss: 1.4304 - val_acc: 0.4834\n",
      "Epoch 19/500\n",
      "100/100 [==============================] - 0s - loss: 0.9996 - acc: 0.6830 - val_loss: 0.9781 - val_acc: 0.7305\n",
      "Epoch 20/500\n",
      "100/100 [==============================] - 0s - loss: 0.8997 - acc: 0.7454 - val_loss: 1.0353 - val_acc: 0.7334\n",
      "Epoch 21/500\n",
      "100/100 [==============================] - 0s - loss: 0.8774 - acc: 0.7516 - val_loss: 0.8712 - val_acc: 0.7168\n",
      "Epoch 22/500\n",
      "100/100 [==============================] - 0s - loss: 0.8590 - acc: 0.7470 - val_loss: 1.0196 - val_acc: 0.7188\n",
      "Epoch 23/500\n",
      "100/100 [==============================] - 0s - loss: 0.8312 - acc: 0.7632 - val_loss: 0.9954 - val_acc: 0.7510\n",
      "Epoch 24/500\n",
      "100/100 [==============================] - 0s - loss: 0.7987 - acc: 0.7760 - val_loss: 0.7865 - val_acc: 0.7939\n",
      "Epoch 25/500\n",
      "100/100 [==============================] - 0s - loss: 0.8173 - acc: 0.7458 - val_loss: 0.7699 - val_acc: 0.7451\n",
      "Epoch 26/500\n",
      "100/100 [==============================] - 0s - loss: 0.7795 - acc: 0.7745 - val_loss: 0.8297 - val_acc: 0.7588\n",
      "Epoch 27/500\n",
      "100/100 [==============================] - 0s - loss: 0.7378 - acc: 0.8037 - val_loss: 0.9174 - val_acc: 0.7773\n",
      "Epoch 28/500\n",
      "100/100 [==============================] - 0s - loss: 0.8129 - acc: 0.7414 - val_loss: 0.8335 - val_acc: 0.8193\n",
      "Epoch 29/500\n",
      "100/100 [==============================] - 0s - loss: 0.6958 - acc: 0.8248 - val_loss: 0.8210 - val_acc: 0.8418\n",
      "Epoch 30/500\n",
      "100/100 [==============================] - 0s - loss: 0.6794 - acc: 0.8317 - val_loss: 0.8364 - val_acc: 0.7803\n",
      "Epoch 31/500\n",
      "100/100 [==============================] - 0s - loss: 0.6773 - acc: 0.8314 - val_loss: 0.7723 - val_acc: 0.7939\n",
      "Epoch 32/500\n",
      "100/100 [==============================] - 0s - loss: 0.6618 - acc: 0.8309 - val_loss: 0.7487 - val_acc: 0.8301\n",
      "Epoch 33/500\n",
      "100/100 [==============================] - 0s - loss: 0.6363 - acc: 0.8429 - val_loss: 0.7164 - val_acc: 0.8125\n",
      "Epoch 34/500\n",
      "100/100 [==============================] - 0s - loss: 0.6259 - acc: 0.8425 - val_loss: 0.6516 - val_acc: 0.8486\n",
      "Epoch 35/500\n",
      "100/100 [==============================] - 0s - loss: 0.6156 - acc: 0.8446 - val_loss: 0.7240 - val_acc: 0.8242\n",
      "Epoch 36/500\n",
      "100/100 [==============================] - 0s - loss: 0.6237 - acc: 0.8371 - val_loss: 0.8583 - val_acc: 0.7920\n",
      "Epoch 37/500\n",
      "100/100 [==============================] - 0s - loss: 0.8003 - acc: 0.7442 - val_loss: 0.5798 - val_acc: 0.8340\n",
      "Epoch 38/500\n",
      "100/100 [==============================] - 0s - loss: 0.5631 - acc: 0.8769 - val_loss: 0.7469 - val_acc: 0.8467\n",
      "Epoch 39/500\n",
      "100/100 [==============================] - 0s - loss: 0.5655 - acc: 0.8667 - val_loss: 0.6488 - val_acc: 0.8418\n",
      "Epoch 40/500\n",
      "100/100 [==============================] - 0s - loss: 0.5416 - acc: 0.8802 - val_loss: 0.5502 - val_acc: 0.8701\n",
      "Epoch 41/500\n",
      "100/100 [==============================] - 0s - loss: 0.5339 - acc: 0.8802 - val_loss: 0.5777 - val_acc: 0.8496\n",
      "Epoch 42/500\n",
      "100/100 [==============================] - 0s - loss: 0.5227 - acc: 0.8874 - val_loss: 0.6184 - val_acc: 0.8730\n",
      "Epoch 43/500\n",
      "100/100 [==============================] - 0s - loss: 0.5190 - acc: 0.8870 - val_loss: 0.5471 - val_acc: 0.9072\n",
      "Epoch 44/500\n",
      "100/100 [==============================] - 0s - loss: 0.5141 - acc: 0.8905 - val_loss: 0.5812 - val_acc: 0.8818\n",
      "Epoch 45/500\n",
      "100/100 [==============================] - 0s - loss: 0.4947 - acc: 0.8931 - val_loss: 0.7145 - val_acc: 0.8877\n",
      "Epoch 46/500\n",
      "100/100 [==============================] - 0s - loss: 0.4934 - acc: 0.8926 - val_loss: 0.6409 - val_acc: 0.8389\n",
      "Epoch 47/500\n",
      "100/100 [==============================] - 0s - loss: 0.4914 - acc: 0.8854 - val_loss: 0.6732 - val_acc: 0.8525\n",
      "Epoch 48/500\n",
      "100/100 [==============================] - 0s - loss: 0.4928 - acc: 0.8889 - val_loss: 0.4972 - val_acc: 0.8975\n",
      "Epoch 49/500\n",
      "100/100 [==============================] - 0s - loss: 0.4694 - acc: 0.8969 - val_loss: 0.6075 - val_acc: 0.8828\n",
      "Epoch 50/500\n",
      "100/100 [==============================] - 0s - loss: 0.4679 - acc: 0.9028 - val_loss: 0.5064 - val_acc: 0.8857\n",
      "Epoch 51/500\n",
      "100/100 [==============================] - 0s - loss: 0.4769 - acc: 0.8823 - val_loss: 0.4842 - val_acc: 0.8721\n",
      "Epoch 52/500\n",
      "100/100 [==============================] - 0s - loss: 0.5664 - acc: 0.8356 - val_loss: 0.7107 - val_acc: 0.8770\n",
      "Epoch 53/500\n",
      "100/100 [==============================] - 0s - loss: 0.4312 - acc: 0.9123 - val_loss: 0.4618 - val_acc: 0.9043\n",
      "Epoch 54/500\n",
      "100/100 [==============================] - 0s - loss: 0.4280 - acc: 0.9116 - val_loss: 0.4991 - val_acc: 0.8750\n",
      "Epoch 55/500\n",
      "100/100 [==============================] - 0s - loss: 0.4170 - acc: 0.9179 - val_loss: 0.4120 - val_acc: 0.9004\n",
      "Epoch 56/500\n",
      "100/100 [==============================] - 0s - loss: 0.4159 - acc: 0.9146 - val_loss: 0.5805 - val_acc: 0.8838\n",
      "Epoch 57/500\n",
      "100/100 [==============================] - 0s - loss: 0.4096 - acc: 0.9185 - val_loss: 0.5052 - val_acc: 0.9160\n",
      "Epoch 58/500\n",
      "100/100 [==============================] - 0s - loss: 0.4064 - acc: 0.9232 - val_loss: 0.5212 - val_acc: 0.9033\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s - loss: 0.4029 - acc: 0.9187 - val_loss: 0.4249 - val_acc: 0.8936\n",
      "Epoch 60/500\n",
      "100/100 [==============================] - 0s - loss: 0.3943 - acc: 0.9213 - val_loss: 0.4317 - val_acc: 0.9072\n",
      "Epoch 61/500\n",
      "100/100 [==============================] - 0s - loss: 0.3925 - acc: 0.9243 - val_loss: 0.5603 - val_acc: 0.8906\n",
      "Epoch 62/500\n",
      "100/100 [==============================] - 0s - loss: 0.3863 - acc: 0.9251 - val_loss: 0.5976 - val_acc: 0.9072\n",
      "Epoch 63/500\n",
      "100/100 [==============================] - 0s - loss: 0.3709 - acc: 0.9283 - val_loss: 0.4403 - val_acc: 0.9043\n",
      "Epoch 64/500\n",
      "100/100 [==============================] - 0s - loss: 0.3780 - acc: 0.9219 - val_loss: 0.4713 - val_acc: 0.9365\n",
      "Epoch 65/500\n",
      "100/100 [==============================] - 0s - loss: 0.3702 - acc: 0.9237 - val_loss: 0.4662 - val_acc: 0.9307\n",
      "Epoch 66/500\n",
      "100/100 [==============================] - 0s - loss: 0.3588 - acc: 0.9334 - val_loss: 0.4044 - val_acc: 0.9443\n",
      "Epoch 67/500\n",
      "100/100 [==============================] - 0s - loss: 0.3539 - acc: 0.9344 - val_loss: 0.4232 - val_acc: 0.9502\n",
      "Epoch 68/500\n",
      "100/100 [==============================] - 0s - loss: 0.3575 - acc: 0.9303 - val_loss: 0.3637 - val_acc: 0.9033\n",
      "Epoch 69/500\n",
      "100/100 [==============================] - 0s - loss: 0.4058 - acc: 0.9158 - val_loss: 2.7878 - val_acc: 0.3506\n",
      "Epoch 70/500\n",
      "100/100 [==============================] - 0s - loss: 0.7682 - acc: 0.7919 - val_loss: 0.4189 - val_acc: 0.8867\n",
      "Epoch 71/500\n",
      "100/100 [==============================] - 0s - loss: 0.3301 - acc: 0.9379 - val_loss: 0.4348 - val_acc: 0.9131\n",
      "Epoch 72/500\n",
      "100/100 [==============================] - 0s - loss: 0.3290 - acc: 0.9405 - val_loss: 0.3400 - val_acc: 0.9121\n",
      "Epoch 73/500\n",
      "100/100 [==============================] - 0s - loss: 0.3387 - acc: 0.9362 - val_loss: 0.4193 - val_acc: 0.9316\n",
      "Epoch 74/500\n",
      "100/100 [==============================] - 0s - loss: 0.3294 - acc: 0.9406 - val_loss: 0.4279 - val_acc: 0.9180\n",
      "Epoch 75/500\n",
      "100/100 [==============================] - 0s - loss: 0.3214 - acc: 0.9437 - val_loss: 0.3876 - val_acc: 0.9395\n",
      "Epoch 76/500\n",
      "100/100 [==============================] - 0s - loss: 0.3178 - acc: 0.9437 - val_loss: 0.5365 - val_acc: 0.9297\n",
      "Epoch 77/500\n",
      "100/100 [==============================] - 0s - loss: 0.3245 - acc: 0.9401 - val_loss: 0.3574 - val_acc: 0.9590\n",
      "Epoch 78/500\n",
      "100/100 [==============================] - 0s - loss: 0.3150 - acc: 0.9417 - val_loss: 0.4648 - val_acc: 0.9131\n",
      "Epoch 79/500\n",
      "100/100 [==============================] - 0s - loss: 0.3229 - acc: 0.9392 - val_loss: 0.4448 - val_acc: 0.9277\n",
      "Epoch 80/500\n",
      "100/100 [==============================] - 0s - loss: 0.3201 - acc: 0.9435 - val_loss: 0.4029 - val_acc: 0.9150\n",
      "Epoch 81/500\n",
      "100/100 [==============================] - 0s - loss: 0.3151 - acc: 0.9439 - val_loss: 0.3843 - val_acc: 0.9238\n",
      "Epoch 82/500\n",
      "100/100 [==============================] - 0s - loss: 0.3054 - acc: 0.9436 - val_loss: 0.5252 - val_acc: 0.9043\n",
      "Epoch 83/500\n",
      "100/100 [==============================] - 0s - loss: 0.3083 - acc: 0.9464 - val_loss: 0.3495 - val_acc: 0.9365\n",
      "Epoch 84/500\n",
      "100/100 [==============================] - 0s - loss: 0.3089 - acc: 0.9419 - val_loss: 0.4323 - val_acc: 0.9443\n",
      "Epoch 85/500\n",
      "100/100 [==============================] - 0s - loss: 0.3027 - acc: 0.9468 - val_loss: 0.2901 - val_acc: 0.9561\n",
      "Epoch 86/500\n",
      "100/100 [==============================] - 0s - loss: 0.2923 - acc: 0.9486 - val_loss: 0.4138 - val_acc: 0.9414\n",
      "Epoch 87/500\n",
      "100/100 [==============================] - 0s - loss: 0.2977 - acc: 0.9458 - val_loss: 0.4644 - val_acc: 0.9287\n",
      "Epoch 88/500\n",
      "100/100 [==============================] - 0s - loss: 0.2977 - acc: 0.9454 - val_loss: 0.3251 - val_acc: 0.9355\n",
      "Epoch 89/500\n",
      "100/100 [==============================] - 0s - loss: 0.2940 - acc: 0.9454 - val_loss: 0.3703 - val_acc: 0.9473\n",
      "Epoch 90/500\n",
      "100/100 [==============================] - 0s - loss: 0.2897 - acc: 0.9497 - val_loss: 0.4264 - val_acc: 0.9375\n",
      "Epoch 91/500\n",
      "100/100 [==============================] - 0s - loss: 0.2901 - acc: 0.9506 - val_loss: 0.3853 - val_acc: 0.9053\n",
      "Epoch 92/500\n",
      "100/100 [==============================] - 0s - loss: 0.2898 - acc: 0.9495 - val_loss: 0.3531 - val_acc: 0.9375\n",
      "Epoch 93/500\n",
      "100/100 [==============================] - 0s - loss: 0.5295 - acc: 0.8639 - val_loss: 0.3655 - val_acc: 0.9023\n",
      "Epoch 94/500\n",
      "100/100 [==============================] - 0s - loss: 0.2794 - acc: 0.9514 - val_loss: 0.3856 - val_acc: 0.9219\n",
      "Epoch 95/500\n",
      "100/100 [==============================] - 0s - loss: 0.2834 - acc: 0.9511 - val_loss: 0.3782 - val_acc: 0.9707\n",
      "Epoch 96/500\n",
      "100/100 [==============================] - 0s - loss: 0.2741 - acc: 0.9525 - val_loss: 0.4278 - val_acc: 0.9189\n",
      "Epoch 97/500\n",
      "100/100 [==============================] - 0s - loss: 0.2792 - acc: 0.9522 - val_loss: 0.4983 - val_acc: 0.9268\n",
      "Epoch 98/500\n",
      "100/100 [==============================] - 0s - loss: 0.2781 - acc: 0.9491 - val_loss: 0.3389 - val_acc: 0.9570\n",
      "Epoch 99/500\n",
      "100/100 [==============================] - 0s - loss: 0.2699 - acc: 0.9569 - val_loss: 0.3814 - val_acc: 0.9248\n",
      "Epoch 100/500\n",
      "100/100 [==============================] - 0s - loss: 0.2702 - acc: 0.9533 - val_loss: 0.4083 - val_acc: 0.9414\n",
      "Epoch 101/500\n",
      "100/100 [==============================] - 0s - loss: 0.2654 - acc: 0.9546 - val_loss: 0.3782 - val_acc: 0.9248\n",
      "Epoch 102/500\n",
      "100/100 [==============================] - 0s - loss: 0.2672 - acc: 0.9579 - val_loss: 0.4282 - val_acc: 0.9229\n",
      "Epoch 103/500\n",
      "100/100 [==============================] - 0s - loss: 0.2644 - acc: 0.9534 - val_loss: 0.4350 - val_acc: 0.9229\n",
      "Epoch 104/500\n",
      "100/100 [==============================] - 0s - loss: 0.2555 - acc: 0.9556 - val_loss: 0.3969 - val_acc: 0.9365\n",
      "Epoch 105/500\n",
      "100/100 [==============================] - 0s - loss: 0.2624 - acc: 0.9538 - val_loss: 0.2545 - val_acc: 0.9473\n",
      "Epoch 106/500\n",
      "100/100 [==============================] - 0s - loss: 0.2598 - acc: 0.9568 - val_loss: 0.3562 - val_acc: 0.9385\n",
      "Epoch 107/500\n",
      "100/100 [==============================] - 0s - loss: 0.2593 - acc: 0.9580 - val_loss: 0.3580 - val_acc: 0.9346\n",
      "Epoch 108/500\n",
      "100/100 [==============================] - 0s - loss: 0.2477 - acc: 0.9601 - val_loss: 0.3409 - val_acc: 0.9482\n",
      "Epoch 109/500\n",
      "100/100 [==============================] - 0s - loss: 0.2558 - acc: 0.9577 - val_loss: 0.4803 - val_acc: 0.9268\n",
      "Epoch 110/500\n",
      "100/100 [==============================] - 0s - loss: 0.2562 - acc: 0.9559 - val_loss: 0.3288 - val_acc: 0.9619\n",
      "Epoch 111/500\n",
      "100/100 [==============================] - 0s - loss: 0.2550 - acc: 0.9577 - val_loss: 0.3087 - val_acc: 0.9326\n",
      "Epoch 112/500\n",
      "100/100 [==============================] - 0s - loss: 0.2470 - acc: 0.9602 - val_loss: 0.4040 - val_acc: 0.9316\n"
     ]
    }
   ],
   "source": [
    "# experiment settings\n",
    "max_num = 100\n",
    "val_num = 1\n",
    "excludes = np.random.choice(max_num, size=val_num, replace=False)\n",
    "\n",
    "# model parameters\n",
    "num_class = 2*max_num + 1\n",
    "n_hidden_1 = 50\n",
    "n_hidden_2 = 100\n",
    "\n",
    "# training parameters\n",
    "num_epoch = 500\n",
    "batch_size = 1024\n",
    "decay = 0.1\n",
    "learning_rate = 0.1\n",
    "\n",
    "# network architecture\n",
    "input_layer = Input(shape=(2,))\n",
    "x = Dense(n_hidden_1, activation='relu', name='Dense_1')(input_layer)\n",
    "x = Dense(n_hidden_2, activation='relu', name='Dense_2')(x)\n",
    "output_layer = Dense(num_class, activation='softmax', name='Output')(x)\n",
    "\n",
    "# model creation\n",
    "model = Model(input_layer, output_layer)\n",
    "print model.summary()\n",
    "\n",
    "# training model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "K.set_value(model.optimizer.lr, learning_rate)\n",
    "train_gen = data_generator(batch_size=batch_size,\n",
    "                           max_num=max_num,\n",
    "                           excludes=excludes,\n",
    "                           num_class=num_class,\n",
    "                           scaler=scaler)\n",
    "valid_gen = data_generator(batch_size=batch_size,\n",
    "                           max_num=max_num,\n",
    "                           excludes=excludes,\n",
    "                           num_class=num_class,\n",
    "                           scaler=scaler,\n",
    "                           is_train=False)\n",
    "callbacks = [EarlyStopping(monitor='loss', min_delta=0.001, patience=3),\n",
    "             LearningRateScheduler(lambda epoch:learning_rate/(1 + decay * epoch)),\n",
    "             ReduceLROnPlateau(monitor='loss'),\n",
    "             TensorBoard()]\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=100,\n",
    "                              epochs=num_epoch,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=valid_gen,\n",
    "                              validation_steps=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
